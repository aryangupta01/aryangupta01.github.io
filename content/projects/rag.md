+++
title = "Multimodal Rag using Ollama LLAVA"
description = """
This project implements a `Multimodal RAG (Retrieval-Augmented Generation)` system using the `Ollama` framework within `Google Colab`. It integrates `LLM` capabilities with both `text` and `image` modality handling for context-rich question answering. Built on `LangChain` and `FAISS`, the system retrieves relevant image-text pairs and queries `LLaVA` models hosted via Ollama for response generation. Features include `Colab-based Ollama setup`, `local model hosting`, `multimodal vector store`, and a seamless `Python interface` for querying custom datasets.
"""
weight = 2

[extra]
remote_image = "/rag_system1.png"
link_to = "https://github.com/aryangupta01/ML-Projects/tree/main/Multimodal%20Rag%20Ollama%20LLAVA"
+++